{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import linear_model\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def RMSE(y_true, y_pred):\n",
        "    \"\"\"\n",
        "        Relative mean squared error (RMSE)\n",
        "    \"\"\"\n",
        "    numerator = np.sqrt(np.mean(np.power((y_true-y_pred),2)))\n",
        "    denominator = np.sqrt(np.mean(np.power(y_true-np.mean(y_true), 2)))\n",
        "    rmse = numerator / denominator\n",
        "    return rmse\n",
        "\n",
        "def CV(model, X, y, K, plot, **kwargs):\n",
        "    \"\"\"\n",
        "        Cross-validation\n",
        "    \"\"\"\n",
        "\n",
        "    kf = KFold(K, shuffle=True)\n",
        "\n",
        "    # OPTIONAL PLOT\n",
        "    if plot:\n",
        "        fig, axarr = plt.subplots(2,5, figsize=(13,8))\n",
        "        axarr = axarr.flatten()\n",
        "\n",
        "    train_error = []\n",
        "    test_error = []\n",
        "    k = 0\n",
        "    for train_idx, test_idx in kf.split(X):\n",
        "        # Create k'th model for k'th fold\n",
        "        modelk = model(**kwargs)\n",
        "\n",
        "        # Split into training set and test set\n",
        "        X_train, y_train = X[train_idx], y[train_idx]\n",
        "        X_test, y_test = X[test_idx], y[test_idx]\n",
        "\n",
        "        # Fit model on training data\n",
        "        modelk.fit(X_train, y_train)\n",
        "\n",
        "        # Calculate RMSE\n",
        "        train_pred = modelk.predict(X_train)\n",
        "        test_pred = modelk.predict(X_test)\n",
        "        train_error.append(RMSE(y_train, train_pred))\n",
        "        test_error.append(RMSE(y_test, test_pred))\n",
        "\n",
        "        # OPTIONAL PLOT\n",
        "        if plot:\n",
        "            axarr[k].plot(y_test, label=\"True\")\n",
        "            axarr[k].plot(test_pred, label=\"Prediction\")\n",
        "            axarr[k].set_title(\"RMSE: \" + '{0:.6f}'.format(test_error[k]))\n",
        "\n",
        "        k += 1\n",
        "\n",
        "    # OPTIONAL PLOT\n",
        "    if plot:\n",
        "        plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "        plt.show()\n",
        "\n",
        "    return np.mean(train_error), np.mean(test_error)\n",
        "\n",
        "kft = KFold(100, shuffle=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"case1_master/case1/dataCase1.csv\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = ['X96','X97','X98','X99','X100']\n",
        "for col_name in cat_cols:\n",
        "    filler = data[col_name].value_counts().idxmax()\n",
        "    data[col_name].fillna(filler,inplace=True)\n",
        "\n",
        "# ONE HOT ENCODING\n",
        "for col_name in cat_cols:\n",
        "    # print(col_name)\n",
        "    for unique_val in sorted(data[col_name].unique()):\n",
        "        # print(unique_val)\n",
        "        data[col_name + unique_val] = (data[col_name].values==unique_val)*1\n",
        "    del data[col_name]\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_clean = data\n",
        "data_clean.iloc[:,1:] = data_clean.iloc[:,1:].fillna(data_clean.iloc[:,1:].mean())\n",
        "\n",
        "X = data_clean[data_clean[\"Y\"].notnull()].iloc[:,1:].values\n",
        "y = data_clean[data_clean[\"Y\"].notnull()][\"Y\"]\n",
        "y = y.values\n",
        "\n",
        "Xn = data_clean[data_clean[\"Y\"].isnull()].iloc[:,1:].values\n",
        "yn = data_clean[\"Y\"][data_clean[\"Y\"].isnull()].values\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "Xn = (Xn - Xn.mean(axis=0)) / Xn.std(axis=0)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_scores = []\n",
        "K = 10\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_ols = linear_model.LinearRegression\n",
        "train_error, test_error = CV(reg_ols, X, y, K, fit_intercept=True, plot=False)\n",
        "model_scores.append({\"model\":\"OLS\", \"lambda\":0, \"train_error\":train_error, \"test_error\":test_error})\n",
        "print(\"train RMSE={:.3f}\\ntest RMSE={:.3f}\".format(train_error, test_error))\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_lars = linear_model.Lars\n",
        "\n",
        "lambdas = range(1,50,1)\n",
        "train_errors, test_errors = [], []\n",
        "for lambda_ in lambdas:\n",
        "    train_error, test_error = CV(reg_lars, X, y, K, n_nonzero_coefs=lambda_, fit_intercept=True, plot=False)\n",
        "    train_errors.append(train_error)\n",
        "    test_errors.append(test_error)\n",
        "    model_scores.append({\"model\":\"LARS\", \"lambda\":lambda_, \"train_error\":train_error, \"test_error\":test_error})\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.plot(lambdas, train_errors,label='train errors')\n",
        "plt.plot(lambdas, test_errors,label='test errors')\n",
        "plt.legend()\n",
        "plt.title(\"LARS Cross-validation\")\n",
        "plt.xlabel(\"Lambda (non-zero coefficients)\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.savefig(\"lars_cv.png\")\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reg_ridge = linear_model.Ridge\n",
        "\n",
        "lambdas = np.arange(0.1,10,0.05)\n",
        "train_errors, test_errors = [], []\n",
        "for lambda_ in lambdas:\n",
        "    train_error, test_error = CV(reg_ridge, X, y, K, alpha=lambda_, fit_intercept=True, plot=False)\n",
        "    train_errors.append(train_error)\n",
        "    test_errors.append(test_error)\n",
        "    model_scores.append({\"model\":\"RIDGE\", \"lambda\":lambda_, \"train_error\":train_error, \"test_error\":test_error})\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.plot(lambdas, train_errors, label = 'train error')\n",
        "plt.plot(lambdas, test_errors, label = 'test error')\n",
        "plt.title(\"Ridge Regression Cross-validation\")\n",
        "plt.xlabel(\"Lambda (L2-norm)\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.legend()\n",
        "plt.savefig(\"ridge_cv.png\")\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "manual_elastic = linear_model.ElasticNet\n",
        "CV(manual_elastic, X, y, 10, alpha=0.1, l1_ratio=0.9, fit_intercept=True, max_iter=700, plot=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## ELASTIC NET ##\n",
        "reg_elastic = linear_model.ElasticNet\n",
        "\n",
        "lambdas = np.arange(0.1, 1.5, 0.05)\n",
        "kappas = np.arange(0.6, 1.5, 0.05)\n",
        "for lambda_ in lambdas:\n",
        "    for kappa in kappas:\n",
        "        train_error, test_error = CV(reg_elastic, X, y, K, alpha=lambda_, l1_ratio=kappa, max_iter=1000, fit_intercept=True, plot=False)\n",
        "        model_scores.append({\"model\":\"ELASTIC\", \"lambda\":lambda_, \"kappa\":kappa, \"train_error\":train_error, \"test_error\":test_error})"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elastics = sorted(list(filter(lambda x: x[\"model\"]==\"ELASTIC\", model_scores)), key=lambda x:x[\"test_error\"])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lambdas = list(map(lambda x: x[\"lambda\"], elastics))\n",
        "kappas = list(map(lambda x: x[\"kappa\"], elastics))\n",
        "tste = list(map(lambda x: x[\"test_error\"], elastics))\n",
        "\n",
        "plt.figure(figsize=(9,5))\n",
        "plt.scatter(lambdas, kappas,s=80, c=tste,cmap='RdBu')\n",
        "plt.title(\"ElasticNet Cross-validation\")\n",
        "plt.xlabel(\"Lambda 1 (L2-norm)\")\n",
        "plt.ylabel(\"Lambda 2 (L1-norm)\")\n",
        "colorbar = 'RdBu'\n",
        "cbar = plt.colorbar()\n",
        "cbar.ax.set_ylabel(\"RMSE\")\n",
        "plt.savefig(\"elastic_cv.png\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top5 = sorted(model_scores, key=lambda x: x[\"test_error\"])[:5]\n",
        "print(\"Top 5 models:\")\n",
        "top5\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top1 = sorted(model_scores, key=lambda x: x[\"test_error\"])[0]\n",
        "print(\"Best model:\")\n",
        "top1\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_std = np.std(list(map(lambda x: x[\"test_error\"], elastics)))\n",
        "print(\"Test error standard deviation:\", cv_std)\n",
        "\n",
        "onestd = elastics[0][\"test_error\"] + cv_std\n",
        "print(\"Choose least complex model closest to a performance of:\", onestd)\n",
        "\n",
        "top1std = list(filter(lambda x: x[\"test_error\"] > onestd, elastics))[0]\n",
        "top1std"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model1std = linear_model.ElasticNet(alpha=top1std[\"lambda\"], l1_ratio=top1std[\"kappa\"])\n",
        "model1std.fit(X, y)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predn = model1std.predict(Xn)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(13,8))\n",
        "plt.plot(predn)\n",
        "plt.title(\"Predictions of the final model for the test data.\")\n",
        "plt.ylabel(\"Estimate $\\hat{y}$\")\n",
        "plt.xlabel(\"Observation\")\n",
        "plt.savefig(\"test_estimates.png\")\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/Users/dth/.local/share/virtualenvs/CDA-r01Zfh9Z/bin/python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "CDA_env",
      "language": "python",
      "name": "cda_env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}